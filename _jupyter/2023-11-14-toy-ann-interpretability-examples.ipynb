{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title: Toy ANN Interpretability Examples\n",
    "date: 2023-11-14\n",
    "category: AI\n",
    "tags: deep-learning, interpretability, universal-approximation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f3543",
   "metadata": {
    "id": "rpp-MfhDHnmA",
    "papermill": {
     "duration": 0.007831,
     "end_time": "2023-11-14T02:45:20.888633",
     "exception": false,
     "start_time": "2023-11-14T02:45:20.880802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "Generally speaking, [universal approximation theorems](https://en.wikipedia.org/wiki/Universal_approximation_theorem) in theoretical AI research suggest that neural networks can represent diverse functions with the right weights, but they do not provide intuitive mechanistic interpretations of *how* a combination of weights work together to represent the function. Neural network training via optimization procedures aims to find the correct set of weights to represent the function, though this may or may not happen due to potential convergence issues.\n",
    "\n",
    "Despite the \"black box\" nature of some neural networks, in which we are unable to decipher why a set of weights works well, there are some very simple toy networks where we can intuit how a particular neural network architecture will represent a function. While a far cry from some of the cool work being done in the nascent field of [mechanistic interpretability](https://transformer-circuits.pub/2022/mech-interp-essay/index.html), I find the simple examples below rather neat and elegant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f741f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T02:45:20.904943Z",
     "iopub.status.busy": "2023-11-14T02:45:20.904560Z",
     "iopub.status.idle": "2023-11-14T02:45:33.755247Z",
     "shell.execute_reply": "2023-11-14T02:45:33.754466Z"
    },
    "id": "tsXcJvHcgDxg",
    "papermill": {
     "duration": 12.861643,
     "end_time": "2023-11-14T02:45:33.757549",
     "exception": false,
     "start_time": "2023-11-14T02:45:20.895906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8a71e2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T02:45:33.774539Z",
     "iopub.status.busy": "2023-11-14T02:45:33.773645Z",
     "iopub.status.idle": "2023-11-14T02:45:33.778382Z",
     "shell.execute_reply": "2023-11-14T02:45:33.777590Z"
    },
    "id": "mebCJqKanXbk",
    "papermill": {
     "duration": 0.015284,
     "end_time": "2023-11-14T02:45:33.780395",
     "exception": false,
     "start_time": "2023-11-14T02:45:33.765111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# configs\n",
    "x_size = 5\n",
    "n_train = 100000\n",
    "n_test = 10000\n",
    "epochs = 1000\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c762bf1",
   "metadata": {
    "id": "li4SYgAoNIFx",
    "papermill": {
     "duration": 0.00707,
     "end_time": "2023-11-14T02:45:33.794916",
     "exception": false,
     "start_time": "2023-11-14T02:45:33.787846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To start, let's generate simple feature matrices, drawn from a standard Gaussian. As we will see, the inclusion of negative numbers will be relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20fbe6ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T02:45:33.810778Z",
     "iopub.status.busy": "2023-11-14T02:45:33.810520Z",
     "iopub.status.idle": "2023-11-14T02:45:33.830896Z",
     "shell.execute_reply": "2023-11-14T02:45:33.830247Z"
    },
    "id": "mbBXv4D_NS3z",
    "papermill": {
     "duration": 0.030623,
     "end_time": "2023-11-14T02:45:33.832852",
     "exception": false,
     "start_time": "2023-11-14T02:45:33.802229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = np.random.normal(0,1,(n_train,x_size))\n",
    "x_test = np.random.normal(0,1,(n_test,x_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9bb182",
   "metadata": {
    "id": "jmD3dKLcN64o",
    "papermill": {
     "duration": 0.007093,
     "end_time": "2023-11-14T02:45:33.847125",
     "exception": false,
     "start_time": "2023-11-14T02:45:33.840032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we construct one of the simplest possible artificial neural network architectures. The forward pass multiplies each feature by a weight in the $W_1$ column vector, sums the products, and adds a bias term, $b_1$. The scalar result is passed to the ReLu ($max(0, .)$) function, with this output being multiplied by another weight, $w_2$. Another bias term, $b_2$, is added to reach an end result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f763dac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T02:45:33.862669Z",
     "iopub.status.busy": "2023-11-14T02:45:33.862376Z",
     "iopub.status.idle": "2023-11-14T02:45:37.054751Z",
     "shell.execute_reply": "2023-11-14T02:45:37.053940Z"
    },
    "id": "MpIuppZlnVXv",
    "papermill": {
     "duration": 3.202763,
     "end_time": "2023-11-14T02:45:37.057031",
     "exception": false,
     "start_time": "2023-11-14T02:45:33.854268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Input(shape=(x_size,)),\n",
    "        tf.keras.layers.Dense(1, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1)\n",
    "\n",
    "    ]\n",
    ")\n",
    "model.save_weights(\"model.h5\")\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=3e-3)\n",
    "model.compile(optimizer=opt, loss=\"mse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b9fb59",
   "metadata": {
    "id": "pLgN10cum__-",
    "papermill": {
     "duration": 0.007058,
     "end_time": "2023-11-14T02:45:37.072256",
     "exception": false,
     "start_time": "2023-11-14T02:45:37.065198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Summation\n",
    "\n",
    "We can train the above network to approximate a function that simply sums all of its inputs.\n",
    "\n",
    "$$\\mathit{X} =\n",
    "\\begin{bmatrix}\n",
    "x_{1} & \\dots & x_{n}\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "$$\n",
    "f(\\mathit{X}) = \\mathit{X}\\mathbf{1} = \\sum_{i=1}^{n}x_i = x_1 + \\dots + x_n\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "049e633e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T02:45:37.088374Z",
     "iopub.status.busy": "2023-11-14T02:45:37.087743Z",
     "iopub.status.idle": "2023-11-14T02:45:37.094543Z",
     "shell.execute_reply": "2023-11-14T02:45:37.093834Z"
    },
    "id": "pGk3f1eGm-eV",
    "papermill": {
     "duration": 0.017053,
     "end_time": "2023-11-14T02:45:37.096453",
     "exception": false,
     "start_time": "2023-11-14T02:45:37.079400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# f(X)\n",
    "y_train = x_train.sum(axis=1)\n",
    "y_test = x_test.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d88819dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T02:45:37.112636Z",
     "iopub.status.busy": "2023-11-14T02:45:37.111983Z",
     "iopub.status.idle": "2023-11-14T03:10:36.412914Z",
     "shell.execute_reply": "2023-11-14T03:10:36.412020Z"
    },
    "id": "lEk3AAMXn1QL",
    "outputId": "d806befb-ebaf-436b-a6d6-d17c913da950",
    "papermill": {
     "duration": 1499.318407,
     "end_time": "2023-11-14T03:10:36.422247",
     "exception": false,
     "start_time": "2023-11-14T02:45:37.103840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00011352584577239452"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=False)\n",
    "mean_squared_error(y_test, model.predict(x_test, verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ea2ee1",
   "metadata": {
    "id": "oGoaiwzQRPEk",
    "papermill": {
     "duration": 0.007143,
     "end_time": "2023-11-14T03:10:36.436699",
     "exception": false,
     "start_time": "2023-11-14T03:10:36.429556",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see how learned weights and biases connect the network computation, which is really a composite function which we will denote $\\hat{f}(\\mathit{X})$, to the true function, $f(\\mathit{X})$, mathematically\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{f}(\\mathit{X}) &= w_2\\max(0, \\mathit{X}\\mathit{W_1} + b_1) + b_2 \\\\\n",
    "&= w_2\\max(0, b_1 + \\sum_{i=1}^{n}W_{1,i}x_i) + b_2 \\\\\n",
    "&= w_2\\max(0, b_1 + W_{1,1}x_1 + \\dots + W_{1,n}x_n) + b_2 \\\\\n",
    "\\end{align}\n",
    "\n",
    "Temporarily ignoring the potential for the zeroing via the rectifier, we can simplify this to\n",
    "\n",
    "$$\n",
    "\\hat{f}(\\mathit{X}) = w_2b_1 + w_2\\sum_{i=1}^{n}W_{1,i}x_i + b_2\n",
    "$$\n",
    "\n",
    "Ultimately, we just want to recover $\\sum_{i=1}^{n}w_{i}x_i$ with $w_{i} = 1, \\forall_{i \\in \\{1,\\dots,n\\}}$, thus the need to set\n",
    "\\begin{align}\n",
    "W_{1,i} &= w_2^{-1} \\quad \\forall_{i \\in \\{1,\\dots,n\\}}, \\\\\n",
    "b_2 &=  -w_2b_1\n",
    "\\end{align}\n",
    "\n",
    "Importantly, since there are negative numbers in our data and we did choose to include the ReLu activation function, $b_1$ and $w_{1,i}$ must be chosen such that\n",
    "$$\n",
    "b_1 + \\sum_{i=1}^{n}W_{1,i}x_i  > 0,\n",
    "$$\n",
    "\n",
    "which we notice depends on the distribution of $\\mathit{X}$.\n",
    "\n",
    "With this, we can substitute our relations to show that we recover the summation function.\n",
    "\n",
    "\\begin{align}\n",
    "w_2(b_1 + \\sum_{i=1}^{n}w_2^{-1}x_i) - w_2b_1 &= w_2b_1 + w_2\\sum_{i=1}^{n}w_2^{-1}x_i -w_2b_1 \\\\\n",
    "&= \\sum_{i=1}^{n}x_i\n",
    "\\end{align}\n",
    "\n",
    "We can now verify this with the learned weights in the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "966eb0e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T03:10:36.452501Z",
     "iopub.status.busy": "2023-11-14T03:10:36.452191Z",
     "iopub.status.idle": "2023-11-14T03:10:36.460967Z",
     "shell.execute_reply": "2023-11-14T03:10:36.460057Z"
    },
    "id": "Xx8MUT4WpAdm",
    "outputId": "4645f58e-c13b-4ec3-f50e-db36b38aab01",
    "papermill": {
     "duration": 0.018814,
     "end_time": "2023-11-14T03:10:36.462845",
     "exception": false,
     "start_time": "2023-11-14T03:10:36.444031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1 weights: 0.3583921492099762, 0.3583921790122986, 0.3583920896053314, 0.3583921790122986, 0.3583921492099762\n",
      "layer 1 bias: 2.801814556121826\n",
      "layer 2 weights: 2.790241241455078\n",
      "layer 2 bias: -7.817744731903076\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"layer {i+1} weights: \" + \", \".join([str(x) for x in layer.get_weights()[0].flatten().tolist()]))\n",
    "    print(f\"layer {i+1} bias: \" + \", \".join([str(x) for x in layer.get_weights()[1].flatten().tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b7212e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T03:10:36.479496Z",
     "iopub.status.busy": "2023-11-14T03:10:36.478982Z",
     "iopub.status.idle": "2023-11-14T03:10:36.490664Z",
     "shell.execute_reply": "2023-11-14T03:10:36.489828Z"
    },
    "id": "wu8Q-Yz0eMSp",
    "outputId": "8edc1b2f-d591-45ed-e399-4cd09e8e3d0c",
    "papermill": {
     "duration": 0.022448,
     "end_time": "2023-11-14T03:10:36.492609",
     "exception": false,
     "start_time": "2023-11-14T03:10:36.470161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.allclose(\n",
    "    # W_1*w_2 == 1\n",
    "    model.layers[0].get_weights()[0].flatten()*\n",
    "    model.layers[1].get_weights()[0],\n",
    "    1,\n",
    "             atol=1e-3)\n",
    "and\n",
    "np.allclose(\n",
    "    # b_2 == -w_2*b_1\n",
    "    model.layers[1].get_weights()[1].flatten(),\n",
    "    -model.layers[1].get_weights()[0]*model.layers[0].get_weights()[1],\n",
    "    atol = 1e-3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e589f6d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T03:10:36.554336Z",
     "iopub.status.busy": "2023-11-14T03:10:36.553522Z",
     "iopub.status.idle": "2023-11-14T03:10:36.558832Z",
     "shell.execute_reply": "2023-11-14T03:10:36.557817Z"
    },
    "id": "o2pW-SYNRulG",
    "outputId": "a7840bf4-2051-45c3-bba6-efa5fd41bc3a",
    "papermill": {
     "duration": 0.060147,
     "end_time": "2023-11-14T03:10:36.560949",
     "exception": false,
     "start_time": "2023-11-14T03:10:36.500802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(X) = x1 + x2 + x3 + x4 + x5\n"
     ]
    }
   ],
   "source": [
    "# true function\n",
    "print(\n",
    "    \"f(X) = \" + \" + \".join([f\"x{i+1}\" for i in range(x_size)])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3111499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T03:10:36.577496Z",
     "iopub.status.busy": "2023-11-14T03:10:36.577205Z",
     "iopub.status.idle": "2023-11-14T03:10:36.587504Z",
     "shell.execute_reply": "2023-11-14T03:10:36.586597Z"
    },
    "id": "yXBa1TmkSLr7",
    "outputId": "f58122f1-2160-4262-c106-faa8df478e87",
    "papermill": {
     "duration": 0.020821,
     "end_time": "2023-11-14T03:10:36.589425",
     "exception": false,
     "start_time": "2023-11-14T03:10:36.568604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(X) = 1.0*x1 + 1.0*x2 + 1.0*x3 + 1.0*x4 + 1.0*x5 + -0.0\n"
     ]
    }
   ],
   "source": [
    "# approximated function\n",
    "recovered_m = (model.layers[0].get_weights()[0].flatten() * model.layers[1].get_weights()[0]).flatten().tolist()\n",
    "recovered_c = (model.layers[0].get_weights()[1].flatten() * model.layers[1].get_weights()[0] + model.layers[1].get_weights()[1]).flatten()[0]\n",
    "print(\n",
    "    \"f(X) = \" + \" + \".join([f\"{round(recovered_m[i],2)}*x{i+1}\" for i in range(x_size)]) + f\" + {str(round(recovered_c, 2))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eac66b",
   "metadata": {
    "id": "6CR0IefHKypY",
    "papermill": {
     "duration": 0.007524,
     "end_time": "2023-11-14T03:10:36.604677",
     "exception": false,
     "start_time": "2023-11-14T03:10:36.597153",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Weighted Sum + Constant\n",
    "\n",
    "We can now train the same network to approximate a *slightly* more complicated function that multiplies each input by a coefficient, sums them, and then adds a constant, akin to a linear model.\n",
    "\n",
    "$$\n",
    "\\mathit{X} =\n",
    "\\begin{bmatrix}\n",
    "x_{1} & \\dots & x_{n}\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "$$\n",
    "\\mathit{M} =\n",
    "\\begin{bmatrix}\n",
    "m_{1} \\\\\n",
    "\\vdots \\\\\n",
    "m_{n}\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "$$\n",
    "f(\\mathit{X}) = \\mathit{M}^T \\mathit{X} + c = c + \\sum_{i=1}^{n}m_ix_i = m_1x_1 + \\dots + m_nx_n + c\n",
    "$$\n",
    "\n",
    "Note that the summation example above is a special case of this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4f2d4c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T03:10:36.621192Z",
     "iopub.status.busy": "2023-11-14T03:10:36.620914Z",
     "iopub.status.idle": "2023-11-14T03:10:36.634748Z",
     "shell.execute_reply": "2023-11-14T03:10:36.634096Z"
    },
    "id": "qFRQUutcLnM3",
    "papermill": {
     "duration": 0.024286,
     "end_time": "2023-11-14T03:10:36.636654",
     "exception": false,
     "start_time": "2023-11-14T03:10:36.612368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# f(X)\n",
    "m = np.random.normal(0,1,x_size)\n",
    "c = np.random.normal(0,1,1).flatten()[0]\n",
    "y_train = (x_train*m).sum(axis=1) + c\n",
    "y_test = (x_test*m).sum(axis=1) + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "113b0039",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T03:10:36.653484Z",
     "iopub.status.busy": "2023-11-14T03:10:36.653190Z",
     "iopub.status.idle": "2023-11-14T03:35:51.169764Z",
     "shell.execute_reply": "2023-11-14T03:35:51.168795Z"
    },
    "id": "_f84qGBkOb-W",
    "papermill": {
     "duration": 1514.535219,
     "end_time": "2023-11-14T03:35:51.179773",
     "exception": false,
     "start_time": "2023-11-14T03:10:36.644554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00010311098776760997"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"model.h5\")\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=False)\n",
    "mean_squared_error(y_test, model.predict(x_test, verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a230d03",
   "metadata": {
    "id": "_CDBtPKiA4li",
    "papermill": {
     "duration": 0.007801,
     "end_time": "2023-11-14T03:35:51.195430",
     "exception": false,
     "start_time": "2023-11-14T03:35:51.187629",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As we did above, we can derive some relations for optimally learned weights.\n",
    "\n",
    "Recall that\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{f}(\\mathit{X}) &= w_2\\max(0, b_1 + \\sum_{i=1}^{n}W_{1,i}x_i) + b_2\n",
    "\\end{align}\n",
    "\n",
    "and without the ReLU\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{f}(\\mathit{X}) &= w_2b_1 + w_2\\sum_{i=1}^{n}W_{1,i}x_i + b_2 \\\\\n",
    "&= \\underbrace{w_2b_1 + b_2}_c + \\sum_{i=1}^{n}\\underbrace{w_2W_{1,i}}_{m_i}x_i\n",
    "\\end{align}\n",
    "\n",
    "We see that we must select $W_1$, $w_2$, $b_1$, and $b_2$, such that $w_2b_1 + b_2 = c$ and $w_2W_{1,i} = m_i$ $\\forall_{i \\in \\{1,\\dots,n\\}}$.\n",
    "\n",
    "\n",
    "Let's verify these with the learned weights in the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c46fd0d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T03:35:51.213154Z",
     "iopub.status.busy": "2023-11-14T03:35:51.212787Z",
     "iopub.status.idle": "2023-11-14T03:35:51.222912Z",
     "shell.execute_reply": "2023-11-14T03:35:51.221963Z"
    },
    "id": "dTUxGFkJOh6P",
    "papermill": {
     "duration": 0.021385,
     "end_time": "2023-11-14T03:35:51.224802",
     "exception": false,
     "start_time": "2023-11-14T03:35:51.203417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1 weights: 0.589567244052887, 0.01935354806482792, -0.34266069531440735, -0.15244796872138977, 0.07748490571975708\n",
      "layer 1 bias: 2.502786159515381\n",
      "layer 2 weights: 2.4603865146636963\n",
      "layer 2 bias: -7.012039661407471\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"layer {i+1} weights: \" + \", \".join([str(x) for x in layer.get_weights()[0].flatten().tolist()]))\n",
    "    print(f\"layer {i+1} bias: \" + \", \".join([str(x) for x in layer.get_weights()[1].flatten().tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6958fb8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T03:35:51.242869Z",
     "iopub.status.busy": "2023-11-14T03:35:51.242082Z",
     "iopub.status.idle": "2023-11-14T03:35:51.253807Z",
     "shell.execute_reply": "2023-11-14T03:35:51.252957Z"
    },
    "id": "W784tIKoNXcy",
    "papermill": {
     "duration": 0.022577,
     "end_time": "2023-11-14T03:35:51.255632",
     "exception": false,
     "start_time": "2023-11-14T03:35:51.233055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.allclose(\n",
    "    # w_2b_1 + b_2 == c\n",
    "    model.layers[1].get_weights()[0][0]*model.layers[0].get_weights()[1] +\n",
    "    model.layers[1].get_weights()[1],\n",
    "    c,\n",
    "    atol=1e-3)\n",
    "and\n",
    " np.allclose(\n",
    "    # w2w_1,i = m_i\n",
    "    model.layers[1].get_weights()[0][0]*model.layers[0].get_weights()[0].flatten(),\n",
    "    m,\n",
    "    atol=1e-3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7253f8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T03:35:51.274433Z",
     "iopub.status.busy": "2023-11-14T03:35:51.273842Z",
     "iopub.status.idle": "2023-11-14T03:35:51.278983Z",
     "shell.execute_reply": "2023-11-14T03:35:51.278119Z"
    },
    "id": "ZRrdEsINLbzx",
    "papermill": {
     "duration": 0.01728,
     "end_time": "2023-11-14T03:35:51.281041",
     "exception": false,
     "start_time": "2023-11-14T03:35:51.263761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(X) = 1.45*x1 + 0.05*x2 + -0.84*x3 + -0.38*x4 + 0.19*x5 + -0.85\n"
     ]
    }
   ],
   "source": [
    "# true function\n",
    "print(\n",
    "    \"f(X) = \" + \" + \".join([str(round(x, 2)) + f\"*x{i+1}\" for i,x in enumerate(m)]) + f\" + {str(round(c, 2))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13f244d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T03:35:51.298804Z",
     "iopub.status.busy": "2023-11-14T03:35:51.297976Z",
     "iopub.status.idle": "2023-11-14T03:35:51.308549Z",
     "shell.execute_reply": "2023-11-14T03:35:51.307753Z"
    },
    "id": "_OrMEbtRP7ak",
    "papermill": {
     "duration": 0.021414,
     "end_time": "2023-11-14T03:35:51.310503",
     "exception": false,
     "start_time": "2023-11-14T03:35:51.289089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(X) = 1.45*x1 + 0.05*x2 + -0.84*x3 + -0.38*x4 + 0.19*x5 + -0.85\n"
     ]
    }
   ],
   "source": [
    "# approximated function\n",
    "recovered_m = (model.layers[0].get_weights()[0].flatten() * model.layers[1].get_weights()[0]).flatten().tolist()\n",
    "recovered_c = (model.layers[0].get_weights()[1].flatten() * model.layers[1].get_weights()[0] + model.layers[1].get_weights()[1]).flatten()[0]\n",
    "print(\n",
    "    \"f(X) = \" + \" + \".join([str(round(x, 2)) + f\"*x{i+1}\" for i,x in enumerate(recovered_m)]) + f\" + {str(round(recovered_c, 2))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73cb8d",
   "metadata": {
    "id": "pbucDbykO2Rc",
    "papermill": {
     "duration": 0.008287,
     "end_time": "2023-11-14T03:35:51.326869",
     "exception": false,
     "start_time": "2023-11-14T03:35:51.318582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Product\n",
    "\n",
    "As a final example, consider a product function\n",
    "\n",
    "$$\n",
    "f(\\mathit{X}) = \\prod_{i=1}^{n}x_i = x_1 \\times \\dots \\times x_n\n",
    "$$\n",
    "\n",
    "Up until this point, the representations have been relatively easy because they leverage weighted sums, which directly corresponds to how neural networks compute. Representing the product becomes quite tricky and a rigorous investigation is beyond the scope of this post ([see here](https://stats.stackexchange.com/a/324008)). However, given *a priori* knowledge (and a constraint to positive numbers) we can leverage the fact that\n",
    "$$\n",
    "\\log(\\prod_{i=1}^{n}x_i) = \\log(x_1) + \\dots + \\log(x_n)\n",
    "$$\n",
    "and we get a repeat of the summation representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85d47095",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T03:35:51.344690Z",
     "iopub.status.busy": "2023-11-14T03:35:51.344414Z",
     "iopub.status.idle": "2023-11-14T03:35:51.367690Z",
     "shell.execute_reply": "2023-11-14T03:35:51.366972Z"
    },
    "id": "rsUEH34WO46p",
    "papermill": {
     "duration": 0.034958,
     "end_time": "2023-11-14T03:35:51.369870",
     "exception": false,
     "start_time": "2023-11-14T03:35:51.334912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = np.random.gamma(1, 1,(n_train,x_size))\n",
    "x_test = np.random.gamma(1, 1,(n_test,x_size))\n",
    "x_train_log = np.log(x_train)\n",
    "x_test_log = np.log(x_test)\n",
    "y_train_log = np.log(x_train.prod(axis=1))\n",
    "y_test = x_test.prod(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adfccc6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T03:35:51.387427Z",
     "iopub.status.busy": "2023-11-14T03:35:51.387121Z",
     "iopub.status.idle": "2023-11-14T04:02:13.890849Z",
     "shell.execute_reply": "2023-11-14T04:02:13.889882Z"
    },
    "id": "JJ7x8B5MSQft",
    "papermill": {
     "duration": 1582.523096,
     "end_time": "2023-11-14T04:02:13.901263",
     "exception": false,
     "start_time": "2023-11-14T03:35:51.378167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.515953185392041e-09"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"model.h5\")\n",
    "history = model.fit(x_train_log, y_train_log, epochs=epochs, batch_size=batch_size, verbose=False)\n",
    "mean_squared_error(y_test, np.exp(model.predict(x_test_log, verbose=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "666e54e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T04:02:13.919210Z",
     "iopub.status.busy": "2023-11-14T04:02:13.918887Z",
     "iopub.status.idle": "2023-11-14T04:02:13.928086Z",
     "shell.execute_reply": "2023-11-14T04:02:13.927188Z"
    },
    "id": "lg5S6UvQT6sI",
    "papermill": {
     "duration": 0.020395,
     "end_time": "2023-11-14T04:02:13.929988",
     "exception": false,
     "start_time": "2023-11-14T04:02:13.909593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1 weights: 0.2527722120285034, 0.2527722418308258, 0.2527722418308258, 0.2527722418308258, 0.2527722120285034\n",
      "layer 1 bias: 4.003366947174072\n",
      "layer 2 weights: 3.956125497817993\n",
      "layer 2 bias: -15.83782958984375\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"layer {i+1} weights: \" + \", \".join([str(x) for x in layer.get_weights()[0].flatten().tolist()]))\n",
    "    print(f\"layer {i+1} bias: \" + \", \".join([str(x) for x in layer.get_weights()[1].flatten().tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f48ff329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T04:02:13.948609Z",
     "iopub.status.busy": "2023-11-14T04:02:13.947892Z",
     "iopub.status.idle": "2023-11-14T04:02:13.958994Z",
     "shell.execute_reply": "2023-11-14T04:02:13.958215Z"
    },
    "id": "KG-Culp4UmVk",
    "papermill": {
     "duration": 0.022645,
     "end_time": "2023-11-14T04:02:13.960992",
     "exception": false,
     "start_time": "2023-11-14T04:02:13.938347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.allclose(\n",
    "    # W_1*w_2 == 1\n",
    "    model.layers[0].get_weights()[0].flatten()*\n",
    "    model.layers[1].get_weights()[0],\n",
    "    1,\n",
    "    atol=1e-3)\n",
    "and\n",
    "np.allclose(\n",
    "    # b_2 == -w_2*b_1\n",
    "    model.layers[1].get_weights()[1].flatten(),\n",
    "    -model.layers[1].get_weights()[0]*model.layers[0].get_weights()[1],\n",
    "    atol = 1e-3)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4619.315047,
   "end_time": "2023-11-14T04:02:16.848617",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-14T02:45:17.533570",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
